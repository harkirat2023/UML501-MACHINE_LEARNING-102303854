{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "4de89e92-22f7-4af3-8234-4a70277ba295",
      "cell_type": "code",
      "source": "import numpy as np\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# a) Load and split data \niris = load_iris()\nX = iris.data\ny = iris.target\ntarget_names = iris.target_names\n\n# 80:20 split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# b) Train three different SVM models \nkernels = {\n    'Linear': SVC(kernel='linear', random_state=42),\n    'Polynomial (degree=3)': SVC(kernel='poly', degree=3, random_state=42),\n    'RBF': SVC(kernel='rbf', random_state=42)\n}\n\nresults = {}\n\nprint(\"--- 1. SVM Kernel Comparison (Iris Dataset) ---\")\nprint(f\"Train set size: {X_train.shape[0]} samples\")\nprint(f\"Test set size: {X_test.shape[0]} samples\")\n\nfor kernel_name, model in kernels.items():\n    # Train the model\n    model.fit(X_train, y_train)\n    \n    # Get predictions\n    y_pred = model.predict(X_test)\n    \n    # c) Evaluate each model\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average='weighted')\n    recall = recall_score(y_test, y_pred, average='weighted')\n    f1 = f1_score(y_test, y_pred, average='weighted')\n    \n    # d) Get confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n    \n    results[kernel_name] = {\n        'Accuracy': accuracy,\n        'Precision': precision,\n        'Recall': recall,\n        'F1-Score': f1,\n        'Confusion Matrix': cm\n    }\n\nfor kernel_name, metrics in results.items():\n    print(\"\\n\" + \"=\"*30)\n    print(f\"Kernel: {kernel_name}\")\n    print(\"=\"*30)\n    print(f\"  Accuracy:  {metrics['Accuracy']:.4f}\")\n    print(f\"  Precision: {metrics['Precision']:.4f}\")\n    print(f\"  Recall:    {metrics['Recall']:.4f}\")\n    print(f\"  F1-Score:  {metrics['F1-Score']:.4f}\")\n    print(\"\\n  Confusion Matrix:\")\n    print(\"  (Rows: True, Cols: Predicted)\")\n    \n    cm_str = \"        \" + \"  \".join([name[:4] for name in target_names])\n    print(cm_str)\n    print(\"      \" + \"-\"*(len(cm_str) - 8))\n    for i, row in enumerate(metrics['Confusion Matrix']):\n        print(f\"  {target_names[i][:4]:<6} | {row}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "--- 1. SVM Kernel Comparison (Iris Dataset) ---\nTrain set size: 120 samples\nTest set size: 30 samples\n\n==============================\nKernel: Linear\n==============================\n  Accuracy:  1.0000\n  Precision: 1.0000\n  Recall:    1.0000\n  F1-Score:  1.0000\n\n  Confusion Matrix:\n  (Rows: True, Cols: Predicted)\n        seto  vers  virg\n      ----------------\n  seto   | [10  0  0]\n  vers   | [0 9 0]\n  virg   | [ 0  0 11]\n\n==============================\nKernel: Polynomial (degree=3)\n==============================\n  Accuracy:  1.0000\n  Precision: 1.0000\n  Recall:    1.0000\n  F1-Score:  1.0000\n\n  Confusion Matrix:\n  (Rows: True, Cols: Predicted)\n        seto  vers  virg\n      ----------------\n  seto   | [10  0  0]\n  vers   | [0 9 0]\n  virg   | [ 0  0 11]\n\n==============================\nKernel: RBF\n==============================\n  Accuracy:  1.0000\n  Precision: 1.0000\n  Recall:    1.0000\n  F1-Score:  1.0000\n\n  Confusion Matrix:\n  (Rows: True, Cols: Predicted)\n        seto  vers  virg\n      ----------------\n  seto   | [10  0  0]\n  vers   | [0 9 0]\n  virg   | [ 0  0 11]\n"
        }
      ],
      "execution_count": 1
    },
    {
      "id": "1f360c3c-eb61-4505-a7a3-28a190c1d90c",
      "cell_type": "code",
      "source": "from sklearn.datasets import load_breast_cancer\nfrom sklearn.preprocessing import StandardScaler\n\n# A) Load the dataset \ncancer = load_breast_cancer()\nX_c = cancer.data\ny_c = cancer.target\n\nX_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_c, y_c, test_size=0.2, random_state=42)\n\nprint(\"\\n--- 2. Impact of Feature Scaling (Breast Cancer) ---\")\n\n# B) Train WITHOUT feature scaling \nsvc_unscaled = SVC(kernel='rbf', random_state=42)\nsvc_unscaled.fit(X_train_c, y_train_c)\n\ntrain_acc_unscaled = svc_unscaled.score(X_train_c, y_train_c)\ntest_acc_unscaled = svc_unscaled.score(X_test_c, y_test_c)\n\n# B) Train WITH feature scaling\n# 1. Create and fit the scaler ON THE TRAINING DATA ONLY\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train_c)\n\n# 2. Transform the test data using the *fitted* scaler\nX_test_scaled = scaler.transform(X_test_c)\n\n# 3. Train the new SVM\nsvc_scaled = SVC(kernel='rbf', random_state=42)\nsvc_scaled.fit(X_train_scaled, y_train_c)\n\n\ntrain_acc_scaled = svc_scaled.score(X_train_scaled, y_train_c)\ntest_acc_scaled = svc_scaled.score(X_test_c, y_test_c) # Note: use X_test_c (unscaled) for unscaled model\n\n# C) Compare results\nprint(\"\\nAccuracy Comparison\")\nprint(f\"                      | Training Accuracy | Testing Accuracy\")\nprint(f\"Model WITHOUT Scaling | {train_acc_unscaled:17.4f} | {test_acc_unscaled:16.4f}\")\nprint(f\"Model WITH Scaling    | {train_acc_scaled:17.4f} | {test_acc_scaled:16.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n--- 2. Impact of Feature Scaling (Breast Cancer) ---\n\nAccuracy Comparison\n                      | Training Accuracy | Testing Accuracy\nModel WITHOUT Scaling |            0.9143 |           0.9474\nModel WITH Scaling    |            0.9890 |           0.3772\n"
        }
      ],
      "execution_count": 3
    },
    {
      "id": "ab7501bc-8b33-4d03-a95d-6bd3c549bf41",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}