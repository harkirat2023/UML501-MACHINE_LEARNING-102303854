{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "45122735-5455-46c9-86b7-a35113dfa2ad",
      "cell_type": "markdown",
      "source": "question 1",
      "metadata": {}
    },
    {
      "id": "2b2c2634-f218-443f-8fcb-ee4ccc50c471",
      "cell_type": "code",
      "source": "import numpy as np\nfrom sklearn.metrics import r2_score\nfrom sklearn.preprocessing import StandardScaler\n\nx = np.random.rand(20, 7)\ny = 3 * x[:, 0] + 2 * x[:, 1] + np.random.randn(20) * 0.1 \n\n# Add bias column (for intercept)\nX = np.c_[np.ones(x.shape[0]), x]\n\nscaler = StandardScaler()\nx[:, 1:] = scaler.fit_transform(x[:, 1:])\n\n# Ridge Regression using Gradient Descent\ndef ridge_regression(x, y, lr, lam, epochs=1000):\n    m, n = x.shape\n    w = np.zeros(n) #model weights\n    for _ in range(epochs):\n        y_pred = x.dot(w)\n        grad = (-2/m) * x.T.dot(y - y_pred) + 2 * lam * w\n        grad[0] -= 2 * lam * w[0]   # no regularization for bias term\n        w -= lr * grad\n        \n        if np.any(np.isnan(w)) or np.any(np.isinf(w)):\n            return np.zeros(n), np.inf\n    cost = np.mean((y - x.dot(w))**2) + lam * np.sum(w**2)\n    return w, cost\n\nlrs = [0.0001, 0.001, 0.01, 0.1, 1, 10]\nlams = [1e-15, 1e-10, 1e-5, 1e-3, 0, 1, 10, 20]\nbest = (None, float('inf'), -1)\n\nfor lr in lrs:\n    for lam in lams:\n        w, cost = ridge_regression(x, y, lr, lam)\n        r2 = r2_score(y, x.dot(w))\n        if cost < best[1] and r2 > best[2]:\n            best = (w, cost, r2)\n\nprint(\"Best weights:\", best[0])\nprint(\"Min Cost:\", best[1])\nprint(\"Max R2 Score:\", best[2])",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Best weights: [ 4.66764169  0.6803408  -0.08895294  0.14963576  0.04090136 -0.12017234\n -0.13964323]\nMin Cost: 0.21622003273774665\nMax R2 Score: 0.8407395414239176\n"
        }
      ],
      "execution_count": 1
    },
    {
      "id": "2d41fffd-d6a9-4ce5-9a24-49a73b5bc5c4",
      "cell_type": "markdown",
      "source": "question 4",
      "metadata": {}
    },
    {
      "id": "ca024d44-0be7-42d4-8bde-458ac3de81f2",
      "cell_type": "code",
      "source": "from sklearn.datasets import load_iris\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\nx, y = load_iris(return_X_y=True)\nx = StandardScaler().fit_transform(x)\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n\ndef sigmoid(z):\n    return 1 / (1 + np.exp(-z))\n\n#logistic regression for one-vs-rest\ndef train_lr(x, y, lr=0.1, epochs=1000):\n    m, n = x.shape\n    w = np.zeros(n)\n    for _ in range(epochs):\n        z = x.dot(w)\n        h = sigmoid(z)\n        grad = (1/m) * x.T.dot(h - y)\n        w -= lr * grad\n    return w\n\nweights = []\nfor cls in np.unique(y):\n    y_bin = (y_train == cls).astype(int)\n    weights.append(train_lr(x_train, y_bin))\ndef predict(x):\n    probs = [sigmoid(x.dot(w)) for w in weights]\n    return np.argmax(probs, axis=0)\n\ny_pred = predict(x_test)\nacc = np.mean(y_pred == y_test)\nprint(\"Accuracy:\", acc)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Accuracy: 0.9\n"
        }
      ],
      "execution_count": 7
    },
    {
      "id": "e574fe5d-70b0-4342-a39f-90f83f977be6",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}